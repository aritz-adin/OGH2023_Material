<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>OGH2023 Material - OGH2023_Material</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">OGH2023 Material</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" rel="" target="" aria-current="page">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./OGH_Foundation.html" rel="" target="">
 <span class="menu-text">OpenGeoHub Foundation</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#tidy-geographic-data-with-sf-dplyr-ggplot2-geos-and-friends-robin-lovelace" id="toc-tidy-geographic-data-with-sf-dplyr-ggplot2-geos-and-friends-robin-lovelace" class="nav-link active" data-scroll-target="#tidy-geographic-data-with-sf-dplyr-ggplot2-geos-and-friends-robin-lovelace">Tidy geographic data with sf, dplyr, ggplot2, geos and friends (Robin Lovelace)</a></li>
  <li><a href="#raster-and-vector-data-cubes-in-r-edzer-pebesma" id="toc-raster-and-vector-data-cubes-in-r-edzer-pebesma" class="nav-link" data-scroll-target="#raster-and-vector-data-cubes-in-r-edzer-pebesma">Raster and vector data cubes in R (Edzer Pebesma)</a></li>
  <li><a href="#unsupervised-classification-clustering-of-satellite-images-with-r-krzysztof-dyba" id="toc-unsupervised-classification-clustering-of-satellite-images-with-r-krzysztof-dyba" class="nav-link" data-scroll-target="#unsupervised-classification-clustering-of-satellite-images-with-r-krzysztof-dyba">Unsupervised classification (clustering) of satellite images with R (Krzysztof Dyba)</a></li>
  <li><a href="#cloud-based-analysis-of-earth-observation-data-using-openeo-platform-r-and-python-edzer-pebesma" id="toc-cloud-based-analysis-of-earth-observation-data-using-openeo-platform-r-and-python-edzer-pebesma" class="nav-link" data-scroll-target="#cloud-based-analysis-of-earth-observation-data-using-openeo-platform-r-and-python-edzer-pebesma">Cloud-based analysis of Earth Observation data using openEO Platform, R and Python (Edzer Pebesma)</a></li>
  <li><a href="#environmental-analysis-using-satellite-image-time-series-ewa-grabska-szwagrzyk" id="toc-environmental-analysis-using-satellite-image-time-series-ewa-grabska-szwagrzyk" class="nav-link" data-scroll-target="#environmental-analysis-using-satellite-image-time-series-ewa-grabska-szwagrzyk">Environmental analysis using satellite image time series (Ewa Grabska-Szwagrzyk)</a></li>
  <li><a href="#spatial-ml-model-assessment-and-interpretation-alexander-brenning" id="toc-spatial-ml-model-assessment-and-interpretation-alexander-brenning" class="nav-link" data-scroll-target="#spatial-ml-model-assessment-and-interpretation-alexander-brenning">Spatial ML model assessment and interpretation (Alexander Brenning)</a></li>
  <li><a href="#tools-and-packages-to-query-and-process-sentinel-1-and-sentinel-2-data-with-r-and-python-lorena-abad" id="toc-tools-and-packages-to-query-and-process-sentinel-1-and-sentinel-2-data-with-r-and-python-lorena-abad" class="nav-link" data-scroll-target="#tools-and-packages-to-query-and-process-sentinel-1-and-sentinel-2-data-with-r-and-python-lorena-abad">Tools and packages to query and process Sentinel-1 and Sentinel-2 data with R and Python (Lorena Abad)</a></li>
  <li><a href="#processing-large-openstreetmap-datasets-for-geocomputational-research-robin-lovelace" id="toc-processing-large-openstreetmap-datasets-for-geocomputational-research-robin-lovelace" class="nav-link" data-scroll-target="#processing-large-openstreetmap-datasets-for-geocomputational-research-robin-lovelace">Processing large OpenStreetMap datasets for geocomputational research (Robin Lovelace)</a></li>
  <li><a href="#progress-in-modernizing-and-replacing-infrastructure-packages-in-r-spatial-workflows-roger-bivand" id="toc-progress-in-modernizing-and-replacing-infrastructure-packages-in-r-spatial-workflows-roger-bivand" class="nav-link" data-scroll-target="#progress-in-modernizing-and-replacing-infrastructure-packages-in-r-spatial-workflows-roger-bivand">Progress in modernizing and replacing infrastructure packages in R-spatial workflows (Roger Bivand)</a></li>
  <li><a href="#introduction-to-working-with-spatial-data-in-python-michael-dorman" id="toc-introduction-to-working-with-spatial-data-in-python-michael-dorman" class="nav-link" data-scroll-target="#introduction-to-working-with-spatial-data-in-python-michael-dorman">Introduction to working with spatial data in Python (Michael Dorman)</a></li>
  <li><a href="#processing-geospatial-data-using-juliageo-framework-marteen-pronk" id="toc-processing-geospatial-data-using-juliageo-framework-marteen-pronk" class="nav-link" data-scroll-target="#processing-geospatial-data-using-juliageo-framework-marteen-pronk">Processing geospatial data using JuliaGeo framework (Marteen Pronk)</a></li>
  <li><a href="#parallelization-of-geoprocessing-workflows-in-grass-gis-and-python-caitlin-haedrich" id="toc-parallelization-of-geoprocessing-workflows-in-grass-gis-and-python-caitlin-haedrich" class="nav-link" data-scroll-target="#parallelization-of-geoprocessing-workflows-in-grass-gis-and-python-caitlin-haedrich">Parallelization of geoprocessing workflows in GRASS GIS and Python (Caitlin Haedrich)</a></li>
  <li><a href="#xcube-for-spatiotemporal-data-analysis-and-visualization-alicja-balfanz" id="toc-xcube-for-spatiotemporal-data-analysis-and-visualization-alicja-balfanz" class="nav-link" data-scroll-target="#xcube-for-spatiotemporal-data-analysis-and-visualization-alicja-balfanz">xcube for spatiotemporal data analysis and visualization (Alicja Balfanz)</a></li>
  <li><a href="#data-engineering-for-mobility-data-science-with-python-and-dvc-anita-graser" id="toc-data-engineering-for-mobility-data-science-with-python-and-dvc-anita-graser" class="nav-link" data-scroll-target="#data-engineering-for-mobility-data-science-with-python-and-dvc-anita-graser">Data engineering for Mobility Data Science (with Python and DVC) (Anita Graser)</a></li>
  <li><a href="#mapping-explanation---python-toolchaing-for-spatial-interpretative-machine-learning-jarosław-jasiewicz" id="toc-mapping-explanation---python-toolchaing-for-spatial-interpretative-machine-learning-jarosław-jasiewicz" class="nav-link" data-scroll-target="#mapping-explanation---python-toolchaing-for-spatial-interpretative-machine-learning-jarosław-jasiewicz">Mapping explanation - Python toolchaing for spatial interpretative machine learning (Jarosław Jasiewicz)</a>
  <ul class="collapse">
  <li><a href="#video-sharing-your-geospatial-knowledge-in-the-open-jakub-nowosad" id="toc-video-sharing-your-geospatial-knowledge-in-the-open-jakub-nowosad" class="nav-link" data-scroll-target="#video-sharing-your-geospatial-knowledge-in-the-open-jakub-nowosad">Video: Sharing your geospatial knowledge in the open (Jakub Nowosad)</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">OpenGeoHub Summer School 2023</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p><img src="img/logo.png" class="img-fluid"><a href="https://opengeohub.org/summer-school/opengeohub-summer-school-poznan-2023/" class="uri">https://opengeohub.org/summer-school/opengeohub-summer-school-poznan-2023/</a></p>
<section id="tidy-geographic-data-with-sf-dplyr-ggplot2-geos-and-friends-robin-lovelace" class="level2">
<h2 class="anchored" data-anchor-id="tidy-geographic-data-with-sf-dplyr-ggplot2-geos-and-friends-robin-lovelace">Tidy geographic data with sf, dplyr, ggplot2, geos and friends (<a href="https://www.robinlovelace.net/">Robin Lovelace</a>)</h2>
<p>This lecture will provide an introduction to working with geographic data using R in a ‘tidy’ way. It will focus on using the sf package to read, write, manipulate, and plot geographic data in combination with the tidyverse metapackage. Why use the <strong><code>sf</code></strong> package with the tidyverse? The lecture will outline some of the ideas underlying the tidyverse and how they can speed-up data analysis pipelines, while making data analysis code easier to read and write. We will see how the following lines</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sf)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>can provide a foundation on which the many geographic data analysis problems can be solved. The lecture will also cover on more recently developed packages that integrate with the tidyverse to a greater and lesser extent. We will look at how the <strong><code>geos</code></strong> package, which provides a simple and high-performance interface to the GEOS library for performing geometric operations on geographic data, integrates with the tidyverse. The tidyverse is not the right tool for every data analysis task and we touch on alternatives for working with raster data, with reference to the <strong><code>terra</code></strong> package, and alternative frameworks such as data.table. Finally, we will also look at how the ‘tidy’ philosophy could be implemented in other programming languages, such as Python.</p>
<p>The focus throughout will be on practical skills and using packages effectively within the wider context of project management tools, integrated development environments (we recommend VS Code with appropriate extensions or RStudio), and version control systems.</p>
<p><strong>Material del curso: <a href="https://ogh23.robinlovelace.net/" class="uri">https://ogh23.robinlovelace.net/tidy</a></strong></p>
<p><strong>GitHub repository: <a href="https://github.com/robinlovelace/opengeohub2023" class="uri">https://github.com/robinlovelace/opengeohub2023</a></strong></p>
<p><strong>Enlace a la grabación en Youtube: <a href="https://www.youtube.com/watch?v=CwL_luh2tWs">parte 1</a>, <a href="https://www.youtube.com/watch?v=1sQN6r-u15o">parte 2</a></strong></p>
</section>
<section id="raster-and-vector-data-cubes-in-r-edzer-pebesma" class="level2">
<h2 class="anchored" data-anchor-id="raster-and-vector-data-cubes-in-r-edzer-pebesma">Raster and vector data cubes in R (<a href="https://www.uni-muenster.de/Geoinformatics/en/institute/staff/index.php/119/edzer_pebesma">Edzer Pebesma</a>)</h2>
<p>A common challenge with raster datasets is not only that they come in large files (single Sentinel-2 tiles are around 1 GB), but that many of these files, potentially thousands or millions, are needed to address the area and time period of interest. In 2022, Copernicus, the program that runs all Sentinel satellites, published 160 TB of images per day. This means that a classic pattern in using R consisting of downloading data to local disc, loading the data in memory, and analysing it is not going to work. This lectures describes how large spatial and spatiotemporal datasets can be handled with R, with a focus on packages <strong><code>sf</code></strong> and <strong><code>stars</code></strong>.</p>
<p>For practical use, we classify large datasets as too large:</p>
<ul>
<li>to fit in working memory,</li>
<li>to fit on the local hard drive, or</li>
<li>to download to locally managed infrastructure (such as network attached storage)</li>
</ul>
<p>These three categories may (today) correspond very roughly to Gigabyte-, Terabyte- and Petabyte-sized datasets. Besides size considerations, access and processing speed also play a role, in particular for larger datasets or interactive applications. Cloud native geospatial formats are formats optimised with processing on cloud infrastructure in mind, where costs of computing and storage need to be considered and optimised.</p>
<p><strong>Material del curso: <a href="https://edzer.github.io/OGH23/dc.html" class="uri">https://edzer.github.io/OGH23/dc.html</a> / <a href="https://r-spatial.org/book/">R book</a></strong></p>
<p><strong>GitHub repository: <a href="https://github.com/edzer/OGH23" class="uri">https://github.com/edzer/OGH23</a></strong></p>
<p><strong>Enlace a la grabación en Youtube: <a href="https://www.youtube.com/watch?v=c8omo1tEB-8">parte 1</a>, <a href="https://www.youtube.com/watch?v=hvST0r9F59Y">parte 2</a></strong></p>
</section>
<section id="unsupervised-classification-clustering-of-satellite-images-with-r-krzysztof-dyba" class="level2">
<h2 class="anchored" data-anchor-id="unsupervised-classification-clustering-of-satellite-images-with-r-krzysztof-dyba">Unsupervised classification (clustering) of satellite images with R (<a href="https://researchportal.amu.edu.pl/info/author/UAM223562/Person%2Bprofile%2B%25E2%2580%2593%2BKrzysztof%2BDyba%2B%25E2%2580%2593%2BAdam%2BMickiewicz%2BUniversity?affil=&amp;tab=main&amp;conversationPropagation=begin&amp;sort=&amp;lang=en&amp;pn=1">Krzysztof Dyba</a>)</h2>
<p>Unsupervised classification of satellite images is the process of grouping similar pixels on an image into homogeneous clusters based primarily on their spectral characteristics. This approach does not require reference (labeled) data, unlike supervised classification, therefore it can be used as a method of first choice. Satellite image classification is commonly used in a variety of fields, including environmental monitoring, land cover mapping, and disaster management. The generated thematic maps can be used to identify and monitor changes in land use, and assess the impact of natural disasters.</p>
<p>During this workshop, participants will gain practical knowledge and skills to perform unsupervised classification of Landsat data using the R language. It will be demonstrated step by step how to use and prepare raster data for analysis, popular grouping methods will be discussed and finally we will prepare a land cover map with interpretation of the results. The workshop will also cover the challenges and limitations of unsupervised classification, such as subjective interpretation of results difficulty of selecting the optimal number of clusters, and validation methods for ensuring the accuracy and reliability of results.</p>
<p>The workshop is aimed at beginners, but basic knowledge of GIS and satellite remote sensing is required.</p>
<p><strong>Material del curso: <a href="https://kadyb.github.io/OGH2023/" class="uri">https://kadyb.github.io/OGH2023/</a></strong></p>
<p><strong>GitHub repository: <a href="https://github.com/kadyb/OGH2023" class="uri">https://github.com/kadyb/OGH2023</a></strong></p>
<p><strong>Enlace a la grabación en Youtube: <a href="https://www.youtube.com/watch?v=YJlnxyEpDu4">parte 1</a>, <a href="https://www.youtube.com/watch?v=i06fwdLyZmg">parte 2</a></strong></p>
</section>
<section id="cloud-based-analysis-of-earth-observation-data-using-openeo-platform-r-and-python-edzer-pebesma" class="level2">
<h2 class="anchored" data-anchor-id="cloud-based-analysis-of-earth-observation-data-using-openeo-platform-r-and-python-edzer-pebesma">Cloud-based analysis of Earth Observation data using openEO Platform, R and Python (<a href="https://www.uni-muenster.de/Geoinformatics/en/institute/staff/index.php/119/edzer_pebesma">Edzer Pebesma</a>)</h2>
<p><a href="https://openeo.org/"><strong>openEO</strong></a> Platform holds a large amount of free and open as well as commercial Earth Observation (EO) data which can be accessed and analysed with openEO, an open API that enables cloud computing and EO data access in a unified and reproducible way. Additionally, client libraries are available in R, Python and Javascript. A JupterLab environment and the Web Editor, a graphical interface, allow a direct and interactive development of processing workflows. The platform is developed with a strong user focus and various use cases have been implemented to illustrate the platform capabilities. Currently, three federated backends support the analysis of EO data from pixel to continental scale.<br>
</p>
<p>The future evolution of openEO Platform in terms of data availability and processing capabilities closely linked to community requirements, facilitated by feature requests from users who design their workflows for environmental monitoring and reproducible research purposes. This presentation provides an overview of the completed use cases, the newly added functionalities such as user code sharing, and user interface updates based on the new use cases and user requests. openEO Platform exemplifies how the processing and analysing large amounts of EO data to meaningful information products is becoming easier and largely compliant with FAIR data principles supporting the EO community at large.</p>
<p><strong>openEO documentation: <a href="https://docs.openeo.cloud/" class="uri">https://docs.openeo.cloud/</a></strong></p>
<p><strong>GitHub repository: <a href="https://github.com/edzer/OGH23" class="uri">https://github.com/edzer/OGH23</a></strong></p>
<p><strong>Enlace a la grabación en Youtube: <a href="https://www.youtube.com/watch?v=NurpU0V6JG8">parte 1</a>, <a href="https://www.youtube.com/watch?v=mrY8VKOoz3c">parte 2</a></strong></p>
</section>
<section id="environmental-analysis-using-satellite-image-time-series-ewa-grabska-szwagrzyk" class="level2">
<h2 class="anchored" data-anchor-id="environmental-analysis-using-satellite-image-time-series-ewa-grabska-szwagrzyk">Environmental analysis using satellite image time series (Ewa Grabska-Szwagrzyk)</h2>
<p>Satellite imagery time series offer a powerful means to detect and analyze both short- and long-term changes in the environment. In particular, the availability of open-access data from missions like Landsat (since 1972) and Sentinel (since 2015) has significantly enhanced our ability to study these changes. This workshop aims to explore the use of time series of indices derived from satellite imagery for analyzing various types of land cover changes using the programming language R. The workshop will cover essential preprocessing steps, including outlier removal and handling missing observations, to ensure the quality of the data. Participants will learn how to effectively model time series using different methods. Additionally, the workshop will provide insights into detecting trends and breaks within the time series data. The analysis will focus on a range of objects and encompass both abrupt and gradual changes. Examples of the types of changes that will be explored include urban growth or vegetation succession.</p>
<p><strong>Material del curso: <a href="https://egrabska.github.io/OGH2023/" class="uri">https://egrabska.github.io/OGH2023/</a></strong></p>
<p><strong>GitHub repository: <a href="https://github.com/egrabska/OGH2023" class="uri">https://github.com/egrabska/OGH2023</a></strong></p>
<p><strong>Enlace a la grabación en Youtube: <a href="https://www.youtube.com/watch?v=v_tQDJtCnsQ">parte 1</a>, <a href="https://www.youtube.com/watch?v=glR5hruA4-w">parte 2</a></strong></p>
</section>
<section id="spatial-ml-model-assessment-and-interpretation-alexander-brenning" class="level2">
<h2 class="anchored" data-anchor-id="spatial-ml-model-assessment-and-interpretation-alexander-brenning">Spatial ML model assessment and interpretation (<a href="https://geods.netlify.app/">Alexander Brenning</a>)</h2>
<p>While significant progress has been made towards explaining black-box machine-learning (ML) models, there is still a distinct lack of diagnostic tools that elucidate the spatial behaviour of ML models in terms of predictive skill and variable importance. This contribution proposes spatial prediction error profiles (SPEPs) and spatial variable importance profiles (SVIPs) as novel model-agnostic assessment and interpretation tools for spatial prediction models with a focus on prediction distance. Their suitability is demonstrated in two case studies representing a regionalization task in an environmental-science context, and a classification task from remotely-sensed land cover classification. In these case studies, the SPEPs and SVIPs of geostatistical methods, linear models, random forest, and hybrid algorithms show striking differences but also relevant similarities. Limitations of related cross-validation techniques are outlined, and the case is made that modelers should focus their model assessment and interpretation on the intended spatial prediction horizon. The range of autocorrelation, in contrast, is not a suitable criterion for defining spatial cross-validation test sets. The novel diagnostic tools enrich the toolkit of spatial data science, and may improve ML model interpretation, selection, and design.</p>
<p><strong>GitHub repository: <a href="https://github.com/alexanderbrenning/ogh23_ml" class="uri">https://github.com/alexanderbrenning/ogh23_ml</a></strong></p>
<p><strong>Enlace a la grabación en Youtube: <a href="https://www.youtube.com/watch?v=EYJ7xsjrQ4o">parte 1</a>, <a href="https://www.youtube.com/watch?v=qElU6VzV0Jc">parte 2</a></strong></p>
</section>
<section id="tools-and-packages-to-query-and-process-sentinel-1-and-sentinel-2-data-with-r-and-python-lorena-abad" class="level2">
<h2 class="anchored" data-anchor-id="tools-and-packages-to-query-and-process-sentinel-1-and-sentinel-2-data-with-r-and-python-lorena-abad">Tools and packages to query and process Sentinel-1 and Sentinel-2 data with R and Python (<a href="https://loreabad6.github.io/">Lorena Abad</a>)</h2>
<p>This session focuses on the products from the ESA Copernicus program Sentinel-1 and Sentinel-2. These products can be freely accessed in several manners and through different portals. We will take a look at packages to query the data you need for your analyses using Python and R, switching between platforms when relevant. An introduction on how to process Sentinel data with both platforms will also be covered focusing on the particularities of the sensors.</p>
<p>For Sentinel-1 data access, we will use the <a href="https://search.asf.alaska.edu/">ASF Data Service</a> to query data. There is no need for credentials for querying the data but if you want to try the downloading steps, you will need <a href="https://urs.earthdata.nasa.gov/">Earthdata Login</a> credentials.</p>
<p><strong>Material del curso: <a href="https://loreabad6.github.io/ogh23/" class="uri">https://loreabad6.github.io/ogh23/</a></strong></p>
<p><strong>GitHub repository: <a href="https://github.com/loreabad6/ogh23" class="uri">https://github.com/loreabad6/ogh23</a></strong></p>
<p><strong>Enlace a la grabación en Youtube: <a href="https://www.youtube.com/watch?v=WRxmAhDEQFE">parte 1</a>, <a href="https://www.youtube.com/watch?v=a8X_jFN63Wc">parte 2</a></strong></p>
</section>
<section id="processing-large-openstreetmap-datasets-for-geocomputational-research-robin-lovelace" class="level2">
<h2 class="anchored" data-anchor-id="processing-large-openstreetmap-datasets-for-geocomputational-research-robin-lovelace">Processing large OpenStreetMap datasets for geocomputational research (<a href="https://www.robinlovelace.net/">Robin Lovelace</a>)</h2>
<p>OpenStreetMap (OSM) is a free and openly editable map of the world. Like Wikipedia and unlike government or corperation maintained datasets, OSM is created and maintained by a community of volunteers, making it the premier decentralized and fastest evolving source of geographic vector<br>
data focussed on features relevant to human activity (e.g.&nbsp;roads, buildings, cafes) on planet Earth. Unlike Wikipedia, every data point in OSM has a geographic location and attributes must be structured as key-value pairs. OSM is a rich source of data for geocomputational research, but the decentralized nature of the project and the sheer volume of data. 'Planet.osm' now has more nodes than there are people on Earth, with more than 8 billion <a href="https://wiki.openstreetmap.org/wiki/Node">nodes</a>, and the rate of data creation is increasing as the community grows, to <a href="https://wiki.openstreetmap.org/wiki/Stats">10 million users</a> in early 2023. The size and rapid evolution of OSM are great strengths, democratising geographic knowledge and ensuring resilience. However, these features can make it difficult to work with OSM data. This lecture will provide an introduction to working with OSM and will cover the following:</p>
<ul>
<li><p>How and where to download OSM data.</p></li>
<li><p>How to process small amounts of OSM data using the <strong><code>osmdata</code></strong> R package.</p></li>
<li><p>How to process large OSM 'extracts' data with the <strong><code>osmextract</code></strong> R package (<a href="https://docs.ropensci.org/osmextract/">documentation</a>).</p></li>
<li><p>Other command line tools for working with OSM data, including the mature and widely used <code>osmium</code> tool, the <code>pyrosm</code> Python package and the <a href="https://github.com/a-b-street/osm2streets"><code>osm2streets</code></a> web application and Rust codebase.</p></li>
</ul>
<p>Finally, the lecture will outline ideas for using OSM data. It will conclude with a call to action, inspiring the use of this rich resource to support policy objectives such as the fast and fair decarbonisation of the global economy as societies transition away from inefficient, polluting and costly fossil fuels.</p>
<p><strong>Material del curso: <a href="https://ogh23.robinlovelace.net/osm" class="uri">https://ogh23.robinlovelace.net/osm</a></strong></p>
<p><strong>GitHub repository: <a href="https://github.com/robinlovelace/opengeohub2023" class="uri">https://github.com/robinlovelace/opengeohub2023</a></strong></p>
</section>
<section id="progress-in-modernizing-and-replacing-infrastructure-packages-in-r-spatial-workflows-roger-bivand" class="level2">
<h2 class="anchored" data-anchor-id="progress-in-modernizing-and-replacing-infrastructure-packages-in-r-spatial-workflows-roger-bivand">Progress in modernizing and replacing infrastructure packages in R-spatial workflows (Roger Bivand)</h2>
<p>Until June 2023, maintainers of legacy packages using <strong><code>rgdal</code></strong>, <strong><code>rgeos</code></strong> and/or <strong><code>maptools</code></strong> were encouraged to migrate to <strong><code>sf</code></strong>/<strong><code>stars</code></strong> or <strong><code>terra</code></strong>, as described in <a href="https://github.com/r-spatial/evolution" class="uri">https://github.com/r-spatial/evolution</a> and blogs listed there: <a href="https://r-spatial.org/r/2022/04/12/evolution.html" class="uri">https://r-spatial.org/r/2022/04/12/evolution.html</a>, <a href="https://r-spatial.org/r/2022/12/14/evolution2.html" class="uri">https://r-spatial.org/r/2022/12/14/evolution2.html</a>, <a href="https://r-spatial.org/r/2023/04/10/evolution3.html" class="uri">https://r-spatial.org/r/2023/04/10/evolution3.html</a>.</p>
<p>In June 2023, <strong><code>sp</code></strong> switches from using <strong><code>rgdal</code></strong> by default for <code>sp::CRS</code> and <code>sp::spTransform</code> to using <strong><code>sf</code></strong> functionality by default.</p>
<p>From October 2023, retiring packages <strong><code>rgdal</code></strong>, <strong><code>rgeos</code></strong> and <strong><code>maptools</code></strong> will be archived on CRAN. This means that residual installations of retiring packages will continue for R 4.2 and R 4.3, but will not be updated after October 2023, nor will they be available for R 4.4.</p>
<p>The workshop will present current status, and may assist participants with affected workflows to adapt; the same applies to key affected packages needed in participants’ workflows. Participants are invited to contact the presenter with practical ideas to packages to adapt, and time may also be used to prepare non-maintainer update candidates for non-responsive packages. The count of affected packages was over 800, but the severity of the impact of the withdrawal of the retiring packages varies by the dependency category, strong dependence as Depends or Imports, weak dependence as Suggests.</p>
<p><strong>Material del curso: <a href="https://r-spatial.github.io/evolution/ogh23_bivand.html" class="uri">https://r-spatial.github.io/evolution/ogh23_bivand.html</a></strong></p>
<p><strong>GitHub repository: <a href="https://github.com/r-spatial/evolution" class="uri">https://github.com/r-spatial/evolution</a></strong></p>
</section>
<section id="introduction-to-working-with-spatial-data-in-python-michael-dorman" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-working-with-spatial-data-in-python-michael-dorman">Introduction to working with spatial data in Python (Michael Dorman)</h2>
<p>Python is an extremely popular general-purpose programming language. It is used in a wide range of settings and for various purposes, including for spatial data processing and analysis.</p>
<p>The aim of this tutorial is to give an introduction to methods of working with spatial data using Python. The tutorial will be split into two parts, introducing two central Python packages:</p>
<ul>
<li><p><code>geopandas</code>---For working with vector layers</p></li>
<li><p><code>rasterio</code>---For working with rasters</p></li>
</ul>
<p>The tutorial will demonstrate typical basic workflows of processing spatial data: data input, processing, geo-computation, and exporting of the results. We will use realistic datasets, such as GTFS public transport data and remote sensing products.</p>
<p>By the end of the tutorial, the participants will be able to:</p>
<ul>
<li><p>Import spatial data from files</p></li>
<li><p>Subset and process the data</p></li>
<li><p>Graphically display the data</p></li>
<li><p>Perform spatial calculations (such as calculating distances, or applying raster algebra operators)</p></li>
<li><p>Export the results</p></li>
</ul>
<p>To follow along and reproduce the results on your own computer, the prerequisite is to be able to run Python code in a Jupyter Notebook interface, linked to a Python environment with the two above-mentioned packages installed. Instructions will be sent in advance.</p>
<p><strong>Material del curso: <a href="https://geobgu.xyz/presentations/p_2023_ogh/" class="uri">https://geobgu.xyz/presentations/p_2023_ogh/</a></strong></p>
</section>
<section id="processing-geospatial-data-using-juliageo-framework-marteen-pronk" class="level2">
<h2 class="anchored" data-anchor-id="processing-geospatial-data-using-juliageo-framework-marteen-pronk">Processing geospatial data using JuliaGeo framework (<a href="https://www.evetion.nl/">Marteen Pronk</a>)</h2>
<p>Julia is a programming language that is simple to write and scriptable like Python and R, but fast like C or C++. At 10 years, it’s a young language, so the ecosystem isn’t as large and mature as you want it to be. Maarten Pronk was an early adopter of the language in his research at Deltares, a Dutch research institute. In this lecture(s) he will introduce Julia, his motivation to use it and his OSS journey. Half of the lecture will be non-spatial, while the latter half will focus on the <code>JuliaGeo</code> ecosystem and showcased some of the possibilities of the Julia language.</p>
<p>The <a href="https://github.com/JuliaGeo">JuliaGeo GitHub</a> organization is intended primarily for the collaborative development of packages that are generally applicable across the geospatial and geosciences domains. For dealing with geospatial data, packages from the JuliaGeometry and JuliaImages organizations may also be of interest, and we will aim for good integration with those. Since the JuliaGeo organization aims to provide mostly general tools, more domain specific packages may be better suited for development in domain specific organizations. JuliaClimate is a nice example of such an organization that will be especially interesting to climate, atmosphere and ocean scientists. EcoJulia also provides some tools for generating and downloading spatial data sets, with a focus on ecological applications.</p>
<p><strong>GitHub repository: <a href="https://github.com/evetion/OGH2023" class="uri">https://github.com/evetion/OGH2023</a></strong></p>
</section>
<section id="parallelization-of-geoprocessing-workflows-in-grass-gis-and-python-caitlin-haedrich" class="level2">
<h2 class="anchored" data-anchor-id="parallelization-of-geoprocessing-workflows-in-grass-gis-and-python-caitlin-haedrich">Parallelization of geoprocessing workflows in GRASS GIS and Python (<a href="https://chaedri.github.io/">Caitlin Haedrich</a>)</h2>
<p>High-resolution, continental-scale modeling enabled by modern, massive datasets, requires development of scalable geoprocessing workflows. To enable participants to effectively use available computational resources (laptop, desktop, institutional HPC), we will introduce basic parallelization concepts such as parallelization efficiency and scaling. We will explain various approaches to parallelization in GRASS GIS, an open source geoprocessing engine, that rely on OpenMP, Python and Bash.<br>
</p>
<p>In the hands-on part, participants will speed up an urban growth model by parallelizing different parts of this complex geoprocessing workflow using techniques that are easily applicable to a wide range of analyses and computational resources. The workshop will be running in a Jupyter Notebook environment using GRASS GIS Python API to run GRASS tools and visualize results of the analysis in a reproducible way.</p>
<p>Participants will be able to either run the workshop on their laptops (see instructions) or in a cloud environment (using WholeTale, no installation required).</p>
<p><strong>GitHub repository: <a href="https://github.com/ncsu-geoforall-lab/opengeohub-2023" class="uri">https://github.com/ncsu-geoforall-lab/opengeohub-2023</a></strong></p>
</section>
<section id="xcube-for-spatiotemporal-data-analysis-and-visualization-alicja-balfanz" class="level2">
<h2 class="anchored" data-anchor-id="xcube-for-spatiotemporal-data-analysis-and-visualization-alicja-balfanz">xcube for spatiotemporal data analysis and visualization (Alicja Balfanz)</h2>
<p><a href="https://xcube.readthedocs.io/en/latest/">xcube</a> is an open-source xarray-based Python package and toolkit that has been developed to provide Earth observation (EO) data in an analysis-ready form to users. xcube achieves this by carefully converting EO data sources into self-contained data cubes that can be published in the cloud.</p>
<p>In this session you will learn about the ecosystem around xcube, which allows to access different data sources and turning the inputs into data cubes. These data cubes can then be easily used for spatiotemporal data analysis and visualization. After a brief introduction about the software components, we will go step by step though some example Jupyter notebooks and finally we will dive into a hands-on session with a little challenge.</p>
<p>For the session you will need a laptop with an internet connection, some basic knowledge about Python and already installed <a href="https://docs.conda.io/en/latest/miniconda.html">miniconda</a> which is used to download the necessary Python packages for the session. Prior experience with Jupyter notebooks will be helpful, but not mandatory.</p>
</section>
<section id="data-engineering-for-mobility-data-science-with-python-and-dvc-anita-graser" class="level2">
<h2 class="anchored" data-anchor-id="data-engineering-for-mobility-data-science-with-python-and-dvc-anita-graser">Data engineering for Mobility Data Science (with Python and DVC) (<a href="https://anitagraser.com/">Anita Graser</a>)</h2>
<p>This session introduces <a href="https://movingpandas.org">MovingPandas</a> and <a href="https://dvc.org">DVC</a> for Mobility Data Science.</p>
<p>MovingPandas is a Python library for the analysis and visualization of movement data. It is built on top of GeoPandas and provides functions to analyze, manipulate and plot trajectories. To get a better idea of the type of analytics that MovingPandas supports, visit: <a href="https://movingpandas.org/examples" class="uri">https://movingpandas.org/examples</a></p>
<p>DVC is a data version control (and machine learning experiment tracking) library. It follows a similar logic to source code version control systems (such as Git) and is typically used together with Git to keep track of data and experiments while Git keeps track of the source code. In this session, we will use DVC to keep track of our movement data analytics workflow. Participants are expected to come prepared with a working MovingPandas &amp; DVC Python environment. Basic previous experience with (Geo)Pandas and version control systems (i.e.&nbsp;how pull, commit, push works in Git) is expected.</p>
<p><strong>GitHub repository:</strong> <a href="https://github.com/movingpandas/movingpandas-examples/tree/opengeohub2023" class="uri">https://github.com/movingpandas/movingpandas-examples/tree/opengeohub2023</a></p>
</section>
<section id="mapping-explanation---python-toolchaing-for-spatial-interpretative-machine-learning-jarosław-jasiewicz" class="level2">
<h2 class="anchored" data-anchor-id="mapping-explanation---python-toolchaing-for-spatial-interpretative-machine-learning-jarosław-jasiewicz">Mapping explanation - Python toolchaing for spatial interpretative machine learning (<a href="http://jarekj.home.amu.edu.pl/">Jarosław Jasiewicz</a>)</h2>
<p>The course will present applications of interpretive machine learning methods to geospatial analysis. Interpretive machine learning is a new branch of machine learning that allows the decomposition of black box models. It allows complex, non-linear models to explain the criteria that lead to a result. In the case of geospatial data, it can be used to search for patterns of spatial explanatory factors. The course covers the entire toolchain from data preparation, model training, and the data transformation process, through data analysis and interpretation of the results, to spatial visualization. The toolchain includes tools such as the shap library, selected components of the scikit-learn, geopandas, and matplotlib packages. The course includes a theoretical introduction to interpretive machine learning and how it can be applied to geospatial data. The practical part is built around analysing the U.S. presidential election results Clinton vs.&nbsp;Trump. In the first step, explanatory variables are collected and transformed into <code>shapely numbers</code>. The data transformed in this way will determine the relevance of the explanatory variables and their actual impact on the election outcome in each county. The advantage of shapely numbers is that the variables are automatically weighted, allowing for efficient clustering. The shapely numbers and their clustering results reveal interesting spatial patterns in the electoral process.</p>
<section id="video-sharing-your-geospatial-knowledge-in-the-open-jakub-nowosad" class="level3">
<h3 class="anchored" data-anchor-id="video-sharing-your-geospatial-knowledge-in-the-open-jakub-nowosad">Video: <a href="https://www.youtube.com/watch?v=AUt-GOZJQaY">Sharing your geospatial knowledge in the open</a> (<a href="https://jakubnowosad.com">Jakub Nowosad</a>)</h3>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
</div> <!-- /content -->



</body></html>